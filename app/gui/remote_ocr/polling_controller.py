"""–ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä polling –¥–ª—è Remote OCR"""

import logging
import time

logger = logging.getLogger(__name__)


class PollingControllerMixin:
    """–ú–∏–∫—Å–∏–Ω –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è polling –∑–∞–¥–∞—á"""

    def _refresh_jobs(self, manual: bool = False):
        """–û–±–Ω–æ–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á"""
        if self._is_fetching:
            return
        self._is_fetching = True
        self._is_manual_refresh = manual

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ (–ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏)
        force_full = getattr(self, "_force_full_refresh", False)

        if manual or force_full:
            self.status_label.setText("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞...")
            # –ü—Ä–∏ —Ä—É—á–Ω–æ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∏–ª–∏ –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏ - –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫
            self._executor.submit(self._fetch_jobs_bg)
        elif self._last_server_time and self._jobs_cache:
            # Incremental polling - —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            self._executor.submit(self._fetch_changes_bg)
        else:
            # –ü–µ—Ä–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ - –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫
            self._executor.submit(self._fetch_jobs_bg)

    def _fetch_jobs_bg(self):
        """–§–æ–Ω–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ª–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ –∑–∞–¥–∞—á"""
        client = self._get_client()
        if client is None:
            self._signals.jobs_error.emit("–û—à–∏–±–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞")
            return
        try:
            logger.debug(f"Fetching full jobs list from {client.base_url}")
            jobs, server_time = client.list_jobs(document_id=None)
            logger.debug(f"Fetched {len(jobs)} jobs, server_time={server_time}")
            self._signals.jobs_loaded.emit(jobs, server_time)
        except Exception as e:
            logger.error(
                f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –∑–∞–¥–∞—á –æ—Ç {client.base_url}: {e}",
                exc_info=True,
            )
            self._signals.jobs_error.emit(str(e))

    def _fetch_changes_bg(self):
        """–§–æ–Ω–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–ª—å–∫–æ –∏–∑–º–µ–Ω–µ–Ω–∏–π (incremental polling)"""
        client = self._get_client()
        if client is None:
            self._signals.jobs_error.emit("–û—à–∏–±–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞")
            return
        try:
            logger.debug(f"Fetching job changes since {self._last_server_time}")
            changed_jobs, server_time = client.get_jobs_changes(self._last_server_time)
            logger.debug(f"Fetched {len(changed_jobs)} changed jobs")

            if changed_jobs:
                logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(changed_jobs)} –∏–∑–º–µ–Ω–µ–Ω–∏–π —Å —Å–µ—Ä–≤–µ—Ä–∞")

            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–µ—à –∏–∑–º–µ–Ω—ë–Ω–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏
            for job in changed_jobs:
                self._jobs_cache[job.id] = job

            # –û–±–Ω–æ–≤–ª—è–µ–º server_time
            if server_time:
                self._last_server_time = server_time

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏–∑ –∫–µ—à–∞
            all_jobs = list(self._jobs_cache.values())
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å–æ–∑–¥–∞–Ω–∏—è (–Ω–æ–≤—ã–µ –ø–µ—Ä–≤—ã–º–∏)
            all_jobs.sort(key=lambda j: j.created_at, reverse=True)
            self._signals.jobs_loaded.emit(all_jobs, server_time or self._last_server_time or "")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π: {e}", exc_info=True)
            # –ü—Ä–∏ –æ—à–∏–±–∫–µ incremental - –ù–ï –æ—á–∏—â–∞–µ–º –∫–µ—à, –ø—Ä–æ–±—É–µ–º –ø–æ–ª–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É
            # –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º poll
            self._force_full_refresh = True
            self._signals.jobs_error.emit(str(e))

    def _on_jobs_loaded(self, jobs, server_time: str = ""):
        """–°–ª–æ—Ç: —Å–ø–∏—Å–æ–∫ –∑–∞–¥–∞—á –ø–æ–ª—É—á–µ–Ω"""
        self._is_fetching = False
        self._force_full_refresh = False

        # –õ–æ–≥–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç—É—Å–æ–≤ –∑–∞–¥–∞—á
        for job in jobs:
            cached = self._jobs_cache.get(job.id)
            if cached and cached.status != job.status:
                logger.info(
                    f"–°—Ç–∞—Ç—É—Å –∑–∞–¥–∞—á–∏ {job.id[:8]}... –∏–∑–º–µ–Ω–∏–ª—Å—è: "
                    f"{cached.status} -> {job.status} (progress={job.progress:.0%})"
                )

        # –ü—Ä–∏ –ø–µ—Ä–≤–æ–π –ø–æ–ª–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–µ—à –∏ server_time
        if self._is_manual_refresh or not self._last_server_time:
            self._jobs_cache = {j.id: j for j in jobs}
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º server_time –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
            if server_time:
                self._last_server_time = server_time
            logger.debug(f"Jobs cache initialized with {len(self._jobs_cache)} jobs, server_time={self._last_server_time}")

        # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–µ –∑–∞–¥–∞—á–∏, –∫–æ—Ç–æ—Ä—ã—Ö –µ—â—ë –Ω–µ—Ç –≤ –æ—Ç–≤–µ—Ç–µ —Å–µ—Ä–≤–µ—Ä–∞
        jobs_ids = {j.id for j in jobs}
        merged_jobs = list(jobs)
        current_time = time.time()

        for job_id, (job_info, timestamp) in list(self._optimistic_jobs.items()):
            if job_id in jobs_ids:
                logger.info(
                    f"–ó–∞–¥–∞—á–∞ {job_id[:8]}... –Ω–∞–π–¥–µ–Ω–∞ –≤ –æ—Ç–≤–µ—Ç–µ —Å–µ—Ä–≤–µ—Ä–∞, "
                    "—É–¥–∞–ª—è–µ–º –∏–∑ –æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞"
                )
                self._optimistic_jobs.pop(job_id, None)
            elif current_time - timestamp > 60:
                logger.warning(
                    f"–ó–∞–¥–∞—á–∞ {job_id[:8]}... –≤ –æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω–æ–º —Å–ø–∏—Å–∫–µ –±–æ–ª–µ–µ –º–∏–Ω—É—Ç—ã, "
                    "—É–¥–∞–ª—è–µ–º (—Ç–∞–π–º–∞—É—Ç)"
                )
                self._optimistic_jobs.pop(job_id, None)
            else:
                logger.debug(
                    f"–ó–∞–¥–∞—á–∞ {job_id[:8]}... –µ—â—ë –Ω–µ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ, –¥–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω–æ"
                )
                merged_jobs.insert(0, job_info)

        self._update_table(merged_jobs)
        self.status_label.setText("üü¢ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ")
        self._consecutive_errors = 0

        self._has_active_jobs = any(
            j.status in ("queued", "processing") for j in merged_jobs
        )
        new_interval = (
            self.POLL_INTERVAL_PROCESSING
            if self._has_active_jobs
            else self.POLL_INTERVAL_IDLE
        )
        if self.refresh_timer.interval() != new_interval:
            self.refresh_timer.setInterval(new_interval)

    def _on_jobs_error(self, error_msg: str):
        """–°–ª–æ—Ç: –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ø–∏—Å–∫–∞"""
        self._is_fetching = False
        self.status_label.setText("üî¥ –°–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        self._consecutive_errors += 1

        # –£–≤–µ–¥–æ–º–ª—è–µ–º ConnectionManager –æ –ø—Ä–æ–±–ª–µ–º–µ
        main_window = self.main_window
        if hasattr(main_window, "connection_manager") and main_window.connection_manager:
            main_window.connection_manager.mark_error(error_msg)

        backoff_interval = min(
            self.POLL_INTERVAL_ERROR * (2 ** min(self._consecutive_errors - 1, 3)),
            180000,
        )
        if self.refresh_timer.interval() != backoff_interval:
            self.refresh_timer.setInterval(backoff_interval)
