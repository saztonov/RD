"""–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: annotation.json + ocr_result.html -> result.json"""
from __future__ import annotations

import json
import logging
import os
from copy import deepcopy
from pathlib import Path
from typing import Optional

from rd_core.ocr.generator_common import (
    HTML_FOOTER,
    INHERITABLE_STAMP_FIELDS,
    collect_inheritable_stamp_data_dict,
    get_html_header,
    parse_stamp_json,
    propagate_stamp_data,
)

from .ocr_html_parser import build_segments_from_html

logger = logging.getLogger(__name__)


def _build_crop_url(block_id: str, r2_public_url: str, project_name: str) -> str:
    """–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å URL –∫—Ä–æ–ø–∞ –¥–ª—è –±–ª–æ–∫–∞."""
    return f"{r2_public_url}/tree_docs/{project_name}/crops/{block_id}.pdf"


def merge_ocr_results(
    annotation_path: Path,
    ocr_html_path: Path,
    output_path: Path,
    project_name: Optional[str] = None,
    r2_public_url: Optional[str] = None,
    score_cutoff: int = 90,
    doc_name: Optional[str] = None,
) -> bool:
    """
    –û–±—ä–µ–¥–∏–Ω–∏—Ç—å annotation.json –∏ ocr_result.html –≤ result.json.

    –î–æ–±–∞–≤–ª—è–µ—Ç –∫ –∫–∞–∂–¥–æ–º—É –±–ª–æ–∫—É:
    - ocr_html: HTML-—Ñ—Ä–∞–≥–º–µ–Ω—Ç –±–ª–æ–∫–∞
    - ocr_json: —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–π JSON –∏–∑ ocr_text (–¥–ª—è IMAGE –±–ª–æ–∫–æ–≤)
    - crop_url: —Å—Å—ã–ª–∫–∞ –Ω–∞ –∫—Ä–æ–ø (–¥–ª—è IMAGE –±–ª–æ–∫–æ–≤)
    - ocr_meta: {method, match_score, marker_text_sample}

    Returns:
        True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ, False –ø—Ä–∏ –æ—à–∏–±–∫–µ
    """
    if not r2_public_url:
        r2_public_url = os.getenv("R2_PUBLIC_URL", "https://rd1.svarovsky.ru")

    try:
        if not annotation_path.exists():
            logger.warning(f"annotation.json –Ω–µ –Ω–∞–π–¥–µ–Ω: {annotation_path}")
            return False

        if not ocr_html_path.exists():
            logger.warning(f"ocr_result.html –Ω–µ –Ω–∞–π–¥–µ–Ω: {ocr_html_path}")
            return False

        with open(annotation_path, "r", encoding="utf-8") as f:
            ann = json.load(f)

        expected_ids = [
            b["id"] for p in ann.get("pages", []) for b in p.get("blocks", [])
        ]

        if not expected_ids:
            logger.info("–ù–µ—Ç –±–ª–æ–∫–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(ann, f, ensure_ascii=False, indent=2)
            return True

        with open(ocr_html_path, "r", encoding="utf-8") as f:
            html_text = f.read()

        segments, meta = build_segments_from_html(
            html_text, expected_ids, score_cutoff=score_cutoff
        )

        result = deepcopy(ann)
        missing = []
        matched = 0

        for page in result.get("pages", []):
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º page_number –≤ 1-based –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
            if "page_number" in page:
                page["page_number"] = page["page_number"] + 1
            for blk in page.get("blocks", []):
                bid = blk["id"]
                block_type = blk.get("block_type", "text")

                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º page_index –≤ 1-based –¥–ª—è –≤–Ω–µ—à–Ω–µ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
                if "page_index" in blk:
                    blk["page_index"] = blk["page_index"] + 1

                # HTML —Ñ—Ä–∞–≥–º–µ–Ω—Ç
                blk["ocr_html"] = segments.get(bid, "")
                blk["ocr_meta"] = meta.get(
                    bid, {"method": [], "match_score": 0.0, "marker_text_sample": ""}
                )

                # –î–ª—è IMAGE –±–ª–æ–∫–æ–≤: –ø–∞—Ä—Å–∏–º JSON –∏–∑ ocr_text –∏ –¥–æ–±–∞–≤–ª—è–µ–º crop_url
                if block_type == "image":
                    ocr_text = blk.get("ocr_text", "")
                    parsed_json = parse_stamp_json(ocr_text)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é —Ñ—É–Ω–∫—Ü–∏—é
                    if parsed_json:
                        blk["ocr_json"] = parsed_json

                    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –∫—Ä–æ–ø (–∫—Ä–æ–º–µ —à—Ç–∞–º–ø–æ–≤)
                    if blk.get("category_code") != "stamp":
                        if project_name:
                            blk["crop_url"] = _build_crop_url(
                                bid, r2_public_url, project_name
                            )
                        elif blk.get("image_file"):
                            crop_name = Path(blk["image_file"]).name
                            blk["crop_url"] = f"{r2_public_url}/crops/{crop_name}"

                if blk["ocr_html"]:
                    matched += 1
                else:
                    missing.append(bid)

        # –°–æ–±–∏—Ä–∞–µ–º –æ–±—â–∏–µ –¥–∞–Ω–Ω—ã–µ —à—Ç–∞–º–ø–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é —Ñ—É–Ω–∫—Ü–∏—é)
        inherited_stamp = collect_inheritable_stamp_data_dict(result.get("pages", []))

        # –†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —à—Ç–∞–º–ø–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â—É—é —Ñ—É–Ω–∫—Ü–∏—é)
        for page in result.get("pages", []):
            propagate_stamp_data(page, inherited_stamp)

        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        if missing:
            logger.warning(
                f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ HTML –¥–ª—è {len(missing)} –±–ª–æ–∫–æ–≤. –ü—Ä–∏–º–µ—Ä—ã: {missing[:3]}"
            )

        logger.info(
            f"result.json —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path} ({matched}/{len(expected_ids)} –±–ª–æ–∫–æ–≤ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ)"
        )

        # –†–µ–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML –∏–∑ —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã—Ö ocr_html
        regenerate_html_from_result(result, ocr_html_path, doc_name=doc_name)

        # –†–µ–≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º MD –∏–∑ —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã—Ö ocr_html
        md_path = output_path.parent / "document.md"
        regenerate_md_from_result(result, md_path, doc_name=doc_name)

        return True

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}", exc_info=True)
        return False


def regenerate_md_from_result(
    result: dict, output_path: Path, doc_name: Optional[str] = None
) -> None:
    """–†–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å Markdown —Ñ–∞–π–ª –∏–∑ result.json."""
    from rd_core.ocr.md_generator import generate_md_from_result

    try:
        generate_md_from_result(result, output_path, doc_name=doc_name)
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ —Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ MD: {e}")


def regenerate_html_from_result(
    result: dict, output_path: Path, doc_name: Optional[str] = None
) -> None:
    """
    –†–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å HTML —Ñ–∞–π–ª –∏–∑ result.json —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–º–∏ –±–ª–æ–∫–∞–º–∏.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç ocr_html (—É–∂–µ —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–π –ø–æ –º–∞—Ä–∫–µ—Ä–∞–º) –≤–º–µ—Å—Ç–æ ocr_text.
    """
    if not doc_name:
        doc_name = result.get("pdf_path", "OCR Result")

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–π HTML —à–∞–±–ª–æ–Ω
    html_parts = [get_html_header(doc_name)]

    block_count = 0
    for page in result.get("pages", []):
        page_num = page.get("page_number", "")

        for idx, blk in enumerate(page.get("blocks", [])):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–ª–æ–∫–∏ —à—Ç–∞–º–ø–∞
            if blk.get("category_code") == "stamp":
                continue

            block_id = blk.get("id", "")
            block_type = blk.get("block_type", "text")
            ocr_html = blk.get("ocr_html", "")

            if not ocr_html:
                continue

            block_count += 1

            html_parts.append(f'<div class="block block-type-{block_type}">')
            html_parts.append(
                f'<div class="block-header">–ë–ª–æ–∫ #{idx + 1} (—Å—Ç—Ä. {page_num}) | –¢–∏–ø: {block_type}</div>'
            )
            html_parts.append('<div class="block-content">')
            html_parts.append(f"<p>BLOCK: {block_id}</p>")

            # –î–ª—è IMAGE –±–ª–æ–∫–æ–≤ –¥–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –∫—Ä–æ–ø
            if block_type == "image" and blk.get("crop_url"):
                if "–û—Ç–∫—Ä—ã—Ç—å –∫—Ä–æ–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è" not in ocr_html:
                    crop_url = blk["crop_url"]
                    html_parts.append(
                        f'<p><a href="{crop_url}" target="_blank"><b>üñºÔ∏è –û—Ç–∫—Ä—ã—Ç—å –∫—Ä–æ–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è</b></a></p>'
                    )

            html_parts.append(ocr_html)
            html_parts.append("</div></div>")

    html_parts.append(HTML_FOOTER)

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(html_parts))

    logger.info(
        f"HTML —Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∏–∑ result.json: {output_path} ({block_count} –±–ª–æ–∫–æ–≤)"
    )
