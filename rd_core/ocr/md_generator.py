"""–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä Markdown –∏–∑ OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è LLM)"""
import json as json_module
import logging
import re
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

logger = logging.getLogger(__name__)

# –ü–æ–ª—è —à—Ç–∞–º–ø–∞, –Ω–∞—Å–ª–µ–¥—É–µ–º—ã–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –±–µ–∑ —à—Ç–∞–º–ø–∞
INHERITABLE_STAMP_FIELDS = ("document_code", "project_name", "stage", "organization")


def _get_block_armor_id(block_id: str) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å armor ID –±–ª–æ–∫–∞."""
    clean = block_id.replace("-", "")
    if len(clean) == 11 and all(c in "34679ACDEFGHJKLMNPQRTUVWXY" for c in clean):
        return block_id

    ALPHABET = "34679ACDEFGHJKLMNPQRTUVWXY"

    def num_to_base26(num: int, length: int) -> str:
        if num == 0:
            return ALPHABET[0] * length
        result = []
        while num > 0:
            result.append(ALPHABET[num % 26])
            num //= 26
        while len(result) < length:
            result.append(ALPHABET[0])
        return "".join(reversed(result[-length:]))

    def calculate_checksum(payload: str) -> str:
        char_map = {c: i for i, c in enumerate(ALPHABET)}
        v1, v2, v3 = 0, 0, 0
        for i, char in enumerate(payload):
            val = char_map.get(char, 0)
            v1 += val
            v2 += val * (i + 3)
            v3 += val * (i + 7) * (i + 1)
        return ALPHABET[v1 % 26] + ALPHABET[v2 % 26] + ALPHABET[v3 % 26]

    clean = block_id.replace("-", "").lower()
    hex_prefix = clean[:10]
    num = int(hex_prefix, 16)
    payload = num_to_base26(num, 8)
    checksum = calculate_checksum(payload)
    full_code = payload + checksum
    return f"{full_code[:4]}-{full_code[4:8]}-{full_code[8:]}"


def _parse_stamp_json(ocr_text: Optional[str]) -> Optional[Dict]:
    """–ò–∑–≤–ª–µ—á—å JSON —à—Ç–∞–º–ø–∞ –∏–∑ ocr_text."""
    if not ocr_text:
        return None

    text = ocr_text.strip()
    if not text:
        return None

    if text.startswith("{"):
        try:
            return json_module.loads(text)
        except json_module.JSONDecodeError:
            pass

    json_match = re.search(r"```json\s*([\s\S]*?)\s*```", text)
    if json_match:
        try:
            return json_module.loads(json_match.group(1))
        except json_module.JSONDecodeError:
            pass

    return None


def _find_page_stamp(blocks: List) -> Optional[Dict]:
    """–ù–∞–π—Ç–∏ –¥–∞–Ω–Ω—ã–µ —à—Ç–∞–º–ø–∞ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ."""
    for block in blocks:
        if getattr(block, "category_code", None) == "stamp":
            stamp_data = _parse_stamp_json(block.ocr_text)
            if stamp_data:
                return stamp_data
    return None


def _collect_inheritable_stamp_data(pages: List) -> Optional[Dict]:
    """–°–æ–±—Ä–∞—Ç—å –æ–±—â–∏–µ –ø–æ–ª—è —à—Ç–∞–º–ø–∞ —Å–æ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü."""
    from collections import Counter

    field_values: Dict[str, List] = {field: [] for field in INHERITABLE_STAMP_FIELDS}

    for page in pages:
        stamp_data = _find_page_stamp(page.blocks)
        if stamp_data:
            for field in INHERITABLE_STAMP_FIELDS:
                val = stamp_data.get(field)
                if val:
                    field_values[field].append(val)

    inherited = {}
    for field in INHERITABLE_STAMP_FIELDS:
        values = field_values[field]
        if values:
            counter = Counter(values)
            most_common = counter.most_common(1)[0][0]
            inherited[field] = most_common

    return inherited if inherited else None


def _format_stamp_md(stamp_data: Dict) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —à—Ç–∞–º–ø–∞ –≤ –∫–æ–º–ø–∞–∫—Ç–Ω—É—é —Å—Ç—Ä–æ–∫—É."""
    parts = []

    if stamp_data.get("document_code"):
        parts.append(f"–®–∏—Ñ—Ä: {stamp_data['document_code']}")
    if stamp_data.get("stage"):
        parts.append(f"–°—Ç–∞–¥–∏—è: {stamp_data['stage']}")
    if stamp_data.get("project_name"):
        parts.append(f"–û–±—ä–µ–∫—Ç: {stamp_data['project_name']}")
    if stamp_data.get("organization"):
        parts.append(f"–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è: {stamp_data['organization']}")

    return " | ".join(parts) if parts else ""


def _clean_cell_text(text: str) -> str:
    """–û—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç —è—á–µ–π–∫–∏ —Ç–∞–±–ª–∏—Ü—ã - –∑–∞–º–µ–Ω–∏—Ç—å –ø–µ—Ä–µ–Ω–æ—Å—ã –Ω–∞ –ø—Ä–æ–±–µ–ª—ã."""
    # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –Ω–∞ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'\s*\n\s*', ' ', text)
    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r' +', ' ', text)
    # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º
    return text.strip()


def _is_complex_table(table_html: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–∞–±–ª–∏—Ü–∞ —Å–ª–æ–∂–Ω–æ–π (colspan/rowspan)."""
    return bool(re.search(r'(?:colspan|rowspan)\s*=\s*["\']?\d+', table_html, re.IGNORECASE))


def _table_to_csv(table_html: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–∂–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –≤ CSV-–ø–æ–¥–æ–±–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç."""
    rows = re.findall(r"<tr[^>]*>(.*?)</tr>", table_html, flags=re.DOTALL)
    if not rows:
        return ""

    csv_lines = []
    for row in rows:
        cells = re.findall(r"<t[hd][^>]*>(.*?)</t[hd]>", row, flags=re.DOTALL)
        if cells:
            cleaned = [_clean_cell_text(re.sub(r"<[^>]+>", "", c)) for c in cells]
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ
            cleaned = [c for c in cleaned if c]
            if cleaned:
                csv_lines.append("; ".join(cleaned))

    return "\n".join(csv_lines)


def _table_to_markdown(table_html: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É HTML –≤ Markdown."""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Å–ª–æ–∂–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
    if _is_complex_table(table_html):
        return _table_to_csv(table_html)

    rows = re.findall(r"<tr[^>]*>(.*?)</tr>", table_html, flags=re.DOTALL)
    if not rows:
        return ""

    md_rows = []
    max_cols = 0

    for i, row in enumerate(rows):
        cells = re.findall(r"<t[hd][^>]*>(.*?)</t[hd]>", row, flags=re.DOTALL)
        if not cells:
            continue

        # –û—á–∏—â–∞–µ–º —è—á–µ–π–∫–∏: —É–±–∏—Ä–∞–µ–º HTML –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
        cleaned = []
        for c in cells:
            text = re.sub(r"<[^>]+>", "", c)
            text = _clean_cell_text(text)
            cleaned.append(text)

        max_cols = max(max_cols, len(cleaned))
        md_rows.append("| " + " | ".join(cleaned) + " |")

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏
        if i == 0:
            md_rows.append("|" + "|".join(["---"] * len(cleaned)) + "|")

    return "\n".join(md_rows)


def _html_to_markdown(html: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å HTML –≤ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π Markdown."""
    if not html:
        return ""

    text = html

    # –£–¥–∞–ª—è–µ–º stamp-info –±–ª–æ–∫–∏ (—É–∂–µ –≤ header)
    text = re.sub(r'<div class="stamp-info[^"]*">.*?</div>', "", text, flags=re.DOTALL)

    # –£–¥–∞–ª—è–µ–º BLOCK –º–∞—Ä–∫–µ—Ä—ã (—É–∂–µ –≤ header)
    text = re.sub(r"<p>BLOCK:\s*[A-Z0-9\-]+</p>", "", text)

    # –£–¥–∞–ª—è–µ–º Created, Linked, Grouped (—É–∂–µ –≤ header)
    text = re.sub(r"<p><b>Created:</b>[^<]*</p>", "", text)
    text = re.sub(r"<p><b>Linked block:</b>[^<]*</p>", "", text)
    text = re.sub(r"<p><b>Grouped blocks:</b>[^<]*</p>", "", text)

    # –£–¥–∞–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –∫—Ä–æ–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    text = re.sub(r'<p><a[^>]*>.*?–û—Ç–∫—Ä—ã—Ç—å –∫—Ä–æ–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.*?</a></p>', "", text, flags=re.DOTALL)

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã –ü–ï–†–ï–î –æ—Å—Ç–∞–ª—å–Ω—ã–º HTML
    def process_table_match(match):
        return _table_to_markdown(match.group(0))

    text = re.sub(r"<table[^>]*>.*?</table>", process_table_match, text, flags=re.DOTALL)

    # –ó–∞–≥–æ–ª–æ–≤–∫–∏ - –∫–æ–º–ø–∞–∫—Ç–Ω–æ
    text = re.sub(r"<h1[^>]*>\s*(.*?)\s*</h1>", r"# \1\n", text, flags=re.DOTALL)
    text = re.sub(r"<h2[^>]*>\s*(.*?)\s*</h2>", r"## \1\n", text, flags=re.DOTALL)
    text = re.sub(r"<h3[^>]*>\s*(.*?)\s*</h3>", r"### \1\n", text, flags=re.DOTALL)
    text = re.sub(r"<h4[^>]*>\s*(.*?)\s*</h4>", r"#### \1\n", text, flags=re.DOTALL)

    # –ñ–∏—Ä–Ω—ã–π –∏ –∫—É—Ä—Å–∏–≤
    text = re.sub(r"<b>\s*(.*?)\s*</b>", r"**\1**", text, flags=re.DOTALL)
    text = re.sub(r"<strong>\s*(.*?)\s*</strong>", r"**\1**", text, flags=re.DOTALL)
    text = re.sub(r"<i>\s*(.*?)\s*</i>", r"*\1*", text, flags=re.DOTALL)
    text = re.sub(r"<em>\s*(.*?)\s*</em>", r"*\1*", text, flags=re.DOTALL)

    # –ö–æ–¥
    text = re.sub(r"<code[^>]*>(.*?)</code>", r"`\1`", text, flags=re.DOTALL)
    text = re.sub(r"<pre[^>]*>(.*?)</pre>", r"```\n\1\n```", text, flags=re.DOTALL)

    # –°–ø–∏—Å–∫–∏
    text = re.sub(r"<li>\s*(.*?)\s*</li>", r"- \1\n", text, flags=re.DOTALL)
    text = re.sub(r"<[ou]l[^>]*>", "", text)
    text = re.sub(r"</[ou]l>", "", text)

    # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è - –∫–æ–º–ø–∞–∫—Ç–Ω–æ
    text = re.sub(r'<img[^>]*src="([^"]*)"[^>]*/?>',
                  lambda m: f"[img:{Path(m.group(1)).stem}]" if m.group(1) else "", text)

    # –°—Å—ã–ª–∫–∏
    text = re.sub(r'<a[^>]*href="([^"]*)"[^>]*>(.*?)</a>', r"[\2](\1)", text, flags=re.DOTALL)

    # –ü–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
    text = re.sub(r"<br\s*/?>", "\n", text)

    # –ü–∞—Ä–∞–≥—Ä–∞—Ñ—ã - —É–±–∏—Ä–∞–µ–º —Ç–µ–≥–∏, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç
    text = re.sub(r"<p[^>]*>\s*(.*?)\s*</p>", r"\1\n", text, flags=re.DOTALL)

    # –£–¥–∞–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è HTML —Ç–µ–≥–∏
    text = re.sub(r"<[^>]+>", "", text)

    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º HTML entities
    text = text.replace("&nbsp;", " ")
    text = text.replace("&amp;", "&")
    text = text.replace("&lt;", "<")
    text = text.replace("&gt;", ">")
    text = text.replace("&quot;", '"')
    text = text.replace("&#39;", "'")

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
    text = re.sub(r"[ \t]+", " ", text)
    text = re.sub(r" *\n *", "\n", text)
    text = re.sub(r"\n{3,}", "\n\n", text)
    text = text.strip()

    return text


def _format_json_content_compact(data: Any) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å JSON –∫–æ–Ω—Ç–µ–Ω—Ç –≤ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π Markdown (–¥–ª—è crops)."""
    if isinstance(data, dict):
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ image OCR —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        if "analysis" in data and isinstance(data["analysis"], dict):
            data = data["analysis"]

        parts = []

        # –õ–æ–∫–∞—Ü–∏—è - –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π
        location = data.get("location")
        if location:
            if isinstance(location, dict):
                zone = location.get("zone_name", "")
                grid = location.get("grid_lines", "")
                loc_parts = []
                if zone and zone != "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ":
                    loc_parts.append(zone)
                if grid and grid != "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã":
                    loc_parts.append(f"–æ—Å–∏ {grid}")
                if loc_parts:
                    parts.append(f"**–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ:** {', '.join(loc_parts)}")
            elif location:
                parts.append(f"**–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ:** {location}")

        # –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        if data.get("content_summary"):
            parts.append(data["content_summary"])

        # –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç - —É–±–∏—Ä–∞–µ–º "‚Ä¢" –º–∞—Ä–∫–µ—Ä—ã
        if data.get("clean_ocr_text"):
            clean_text = data["clean_ocr_text"]
            clean_text = re.sub(r"‚Ä¢\s*", "", clean_text)
            clean_text = re.sub(r"\s+", " ", clean_text).strip()
            if clean_text:
                parts.append(f"**–¢–µ–∫—Å—Ç:** {clean_text}")

        # –ö–ª—é—á–µ–≤—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ - –∫–æ–º–ø–∞–∫—Ç–Ω–æ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é
        if data.get("key_entities") and isinstance(data["key_entities"], list):
            entities = ", ".join(data["key_entities"][:15])  # –ú–∞–∫—Å–∏–º—É–º 15
            parts.append(f"**–°—É—â–Ω–æ—Å—Ç–∏:** {entities}")

        if parts:
            return " | ".join(parts)

    # Fallback: –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π JSON
    return json_module.dumps(data, ensure_ascii=False, separators=(',', ':'))


def generate_md_from_pages(
    pages: List,
    output_path: str,
    doc_name: str = None,
    project_name: str = None,
) -> str:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ–≥–æ Markdown —Ñ–∞–π–ª–∞ –∏–∑ OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è LLM.
    """
    try:
        from rd_core.models import BlockType

        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        title = doc_name or "OCR Result"

        # –°–æ–±–∏—Ä–∞–µ–º –±–ª–æ–∫–∏ –ø–æ –≥—Ä—É–ø–ø–∞–º
        groups: Dict[str, List] = {}
        for page in pages:
            for block in page.blocks:
                group_id = getattr(block, "group_id", None)
                if group_id:
                    if group_id not in groups:
                        groups[group_id] = []
                    groups[group_id].append(block)

        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ —à—Ç–∞–º–ø–∞
        inherited_stamp_data = _collect_inheritable_stamp_data(pages)

        md_parts = []

        # === HEADER ===
        md_parts.append(f"# {title}")
        md_parts.append("")
        md_parts.append(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC")

        # –®—Ç–∞–º–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ - –∫–æ–º–ø–∞–∫—Ç–Ω–æ
        if inherited_stamp_data:
            stamp_str = _format_stamp_md(inherited_stamp_data)
            if stamp_str:
                md_parts.append(f"**–®—Ç–∞–º–ø:** {stamp_str}")

        md_parts.append("")
        md_parts.append("---")
        md_parts.append("")

        # === –ë–õ–û–ö–ò - –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º ===
        block_count = 0
        current_page_num = None

        for page in pages:
            page_num = page.page_number + 1 if page.page_number is not None else 0

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –±–ª–æ–∫–∏ –∫—Ä–æ–º–µ —à—Ç–∞–º–ø–æ–≤
            non_stamp_blocks = [b for b in page.blocks if getattr(b, "category_code", None) != "stamp"]
            if not non_stamp_blocks:
                continue

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if page_num != current_page_num:
                current_page_num = page_num
                md_parts.append(f"## –°–¢–†–ê–ù–ò–¶–ê {page_num}")
                md_parts.append("")

            for block in page.blocks:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–ª–æ–∫–∏ —à—Ç–∞–º–ø–∞
                if getattr(block, "category_code", None) == "stamp":
                    continue

                block_count += 1
                armor_code = _get_block_armor_id(block.id)
                block_type = block.block_type.value.upper()

                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∞ - –∫–æ–º–ø–∞–∫—Ç–Ω–æ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É
                meta_parts = [f"[{block_type}]", f"BLOCK:{armor_code}"]

                # Linked block
                linked_id = getattr(block, "linked_block_id", None)
                if linked_id:
                    meta_parts.append(f"‚Üí{_get_block_armor_id(linked_id)}")

                # Grouped blocks
                group_id = getattr(block, "group_id", None)
                if group_id and group_id in groups:
                    group_name = getattr(block, "group_name", None) or "–≥—Ä—É–ø–ø–∞"
                    group_block_ids = [_get_block_armor_id(b.id) for b in groups[group_id]]
                    meta_parts.append(f"üì¶{group_name}[{','.join(group_block_ids)}]")

                md_parts.append(" ".join(meta_parts))

                # –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–ª–æ–∫–∞
                ocr_text = block.ocr_text
                if ocr_text:
                    text = ocr_text.strip()
                    if text.startswith("<"):
                        # HTML –∫–æ–Ω—Ç–µ–Ω—Ç
                        content = _html_to_markdown(text)
                    elif text.startswith("{") or text.startswith("["):
                        # JSON –∫–æ–Ω—Ç–µ–Ω—Ç (crops)
                        try:
                            parsed = json_module.loads(text)
                            content = _format_json_content_compact(parsed)
                        except json_module.JSONDecodeError:
                            content = text
                    else:
                        content = text

                    if content:
                        md_parts.append(content)

                md_parts.append("")

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–π–ª
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("\n".join(md_parts))

        logger.info(f"MD —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_file} ({block_count} –±–ª–æ–∫–æ–≤)")
        return str(output_file)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ MD: {e}", exc_info=True)
        raise


def generate_md_from_result(
    result: dict, output_path: Path, doc_name: Optional[str] = None
) -> None:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å Markdown —Ñ–∞–π–ª –∏–∑ result.json —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–º–∏ –±–ª–æ–∫–∞–º–∏.
    –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º, –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö –±–ª–æ–∫–æ–≤ –∏–∑ annotation.
    """
    if not doc_name:
        doc_name = result.get("pdf_path", "OCR Result")

    md_parts = []

    # === HEADER ===
    md_parts.append(f"# {doc_name}")
    md_parts.append("")
    md_parts.append(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC")

    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ —à—Ç–∞–º–ø–∞ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –±–ª–æ–∫–∞
    first_stamp = None
    for page in result.get("pages", []):
        for blk in page.get("blocks", []):
            if blk.get("stamp_data"):
                first_stamp = blk["stamp_data"]
                break
        if first_stamp:
            break

    if first_stamp:
        stamp_str = _format_stamp_md(first_stamp)
        if stamp_str:
            md_parts.append(f"**–®—Ç–∞–º–ø:** {stamp_str}")

    md_parts.append("")
    md_parts.append("---")
    md_parts.append("")

    # –°–æ–±–∏—Ä–∞–µ–º –≥—Ä—É–ø–ø—ã –±–ª–æ–∫–æ–≤
    groups: Dict[str, List[str]] = {}
    for page in result.get("pages", []):
        for blk in page.get("blocks", []):
            group_id = blk.get("group_id")
            if group_id:
                if group_id not in groups:
                    groups[group_id] = []
                groups[group_id].append(blk.get("id", ""))

    # === –ë–õ–û–ö–ò - –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º ===
    block_count = 0
    current_page_num = None

    for page in result.get("pages", []):
        page_num = page.get("page_number", 0)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –±–ª–æ–∫–∏ –∫—Ä–æ–º–µ —à—Ç–∞–º–ø–æ–≤
        non_stamp_blocks = [b for b in page.get("blocks", []) if b.get("category_code") != "stamp"]
        if not non_stamp_blocks:
            continue

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        if page_num != current_page_num:
            current_page_num = page_num
            md_parts.append(f"## –°–¢–†–ê–ù–ò–¶–ê {page_num}")
            md_parts.append("")

        for blk in page.get("blocks", []):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–ª–æ–∫–∏ —à—Ç–∞–º–ø–∞
            if blk.get("category_code") == "stamp":
                continue

            block_id = blk.get("id", "")
            block_type = blk.get("block_type", "text").upper()
            ocr_html = blk.get("ocr_html", "")
            ocr_text = blk.get("ocr_text", "")

            block_count += 1

            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∞ - –∫–æ–º–ø–∞–∫—Ç–Ω–æ
            meta_parts = [f"[{block_type}]", f"BLOCK:{block_id}"]

            # Linked block
            if blk.get("linked_block_id"):
                meta_parts.append(f"‚Üí{blk['linked_block_id']}")

            # Grouped blocks
            group_id = blk.get("group_id")
            if group_id and group_id in groups:
                group_name = blk.get("group_name") or "–≥—Ä—É–ø–ø–∞"
                group_block_ids = groups[group_id]
                meta_parts.append(f"üì¶{group_name}[{','.join(group_block_ids)}]")

            md_parts.append(" ".join(meta_parts))

            # –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–ª–æ–∫–∞
            content = ""
            if ocr_html:
                content = _html_to_markdown(ocr_html)
            elif ocr_text:
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º ocr_text –Ω–∞–ø—Ä—è–º—É—é
                text = ocr_text.strip()
                if text.startswith("<"):
                    content = _html_to_markdown(text)
                elif text.startswith("{") or text.startswith("["):
                    try:
                        parsed = json_module.loads(text)
                        content = _format_json_content_compact(parsed)
                    except json_module.JSONDecodeError:
                        content = text
                else:
                    content = text

            if content:
                md_parts.append(content)
            else:
                md_parts.append("*(–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö)*")

            md_parts.append("")

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(md_parts))

    logger.info(f"MD —Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∏–∑ result.json: {output_path} ({block_count} –±–ª–æ–∫–æ–≤)")
