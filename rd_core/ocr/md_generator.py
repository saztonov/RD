"""–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä Markdown (_document.md) –∏–∑ OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è LLM)."""
import json as json_module
import logging
import re
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from .generator_common import (
    DATALAB_IMG_PATTERN,
    DATALAB_MD_IMG_PATTERN,
    collect_block_groups,
    collect_inheritable_stamp_data,
    extract_image_ocr_data,
    find_page_stamp,
    get_block_armor_id,
    is_image_ocr_json,
    sanitize_html,
    sanitize_markdown,
)

logger = logging.getLogger(__name__)


def _format_stamp_md(stamp_data: Dict) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ —à—Ç–∞–º–ø–∞ –≤ –∫–æ–º–ø–∞–∫—Ç–Ω—É—é Markdown —Å—Ç—Ä–æ–∫—É."""
    parts = []

    if stamp_data.get("document_code"):
        parts.append(f"–®–∏—Ñ—Ä: {stamp_data['document_code']}")
    if stamp_data.get("stage"):
        parts.append(f"–°—Ç–∞–¥–∏—è: {stamp_data['stage']}")
    if stamp_data.get("project_name"):
        parts.append(f"–û–±—ä–µ–∫—Ç: {stamp_data['project_name']}")
    if stamp_data.get("organization"):
        parts.append(f"–û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è: {stamp_data['organization']}")

    return " | ".join(parts) if parts else ""


def _clean_cell_text(text: str) -> str:
    """–û—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç —è—á–µ–π–∫–∏ —Ç–∞–±–ª–∏—Ü—ã - –∑–∞–º–µ–Ω–∏—Ç—å –ø–µ—Ä–µ–Ω–æ—Å—ã –Ω–∞ –ø—Ä–æ–±–µ–ª—ã."""
    text = re.sub(r'\s*\n\s*', ' ', text)
    text = re.sub(r' +', ' ', text)
    return text.strip()


def _is_complex_table(table_html: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–∞–±–ª–∏—Ü–∞ —Å–ª–æ–∂–Ω–æ–π (colspan/rowspan)."""
    return bool(re.search(r'(?:colspan|rowspan)\s*=\s*["\']?\d+', table_html, re.IGNORECASE))


def _table_to_csv(table_html: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–ª–æ–∂–Ω—É—é —Ç–∞–±–ª–∏—Ü—É –≤ CSV-–ø–æ–¥–æ–±–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç."""
    rows = re.findall(r"<tr[^>]*>(.*?)</tr>", table_html, flags=re.DOTALL)
    if not rows:
        return ""

    csv_lines = []
    for row in rows:
        cells = re.findall(r"<t[hd][^>]*>(.*?)</t[hd]>", row, flags=re.DOTALL)
        if cells:
            cleaned = [_clean_cell_text(re.sub(r"<[^>]+>", "", c)) for c in cells]
            cleaned = [c for c in cleaned if c]
            if cleaned:
                csv_lines.append("; ".join(cleaned))

    return "\n".join(csv_lines)


def _table_to_markdown(table_html: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É HTML –≤ Markdown."""
    if _is_complex_table(table_html):
        return _table_to_csv(table_html)

    rows = re.findall(r"<tr[^>]*>(.*?)</tr>", table_html, flags=re.DOTALL)
    if not rows:
        return ""

    md_rows = []
    max_cols = 0

    for i, row in enumerate(rows):
        cells = re.findall(r"<t[hd][^>]*>(.*?)</t[hd]>", row, flags=re.DOTALL)
        if not cells:
            continue

        cleaned = []
        for c in cells:
            text = re.sub(r"<[^>]+>", "", c)
            text = _clean_cell_text(text)
            cleaned.append(text)

        max_cols = max(max_cols, len(cleaned))
        md_rows.append("| " + " | ".join(cleaned) + " |")

        if i == 0:
            md_rows.append("|" + "|".join(["---"] * len(cleaned)) + "|")

    return "\n".join(md_rows)


def _html_to_markdown(html: str) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å HTML –≤ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π Markdown."""
    if not html:
        return ""

    # –°–Ω–∞—á–∞–ª–∞ —Å–∞–Ω–∏—Ç–∏–∑–∏—Ä—É–µ–º HTML (—É–¥–∞–ª—è–µ–º –º—É—Å–æ—Ä–Ω—ã–µ img –æ—Ç datalab)
    text = sanitize_html(html)

    # –£–¥–∞–ª—è–µ–º stamp-info –±–ª–æ–∫–∏ (—É–∂–µ –≤ header)
    text = re.sub(r'<div class="stamp-info[^"]*">.*?</div>', "", text, flags=re.DOTALL)

    # –£–¥–∞–ª—è–µ–º BLOCK –º–∞—Ä–∫–µ—Ä—ã (—É–∂–µ –≤ header)
    text = re.sub(r"<p>BLOCK:\s*[A-Z0-9\-]+</p>", "", text)

    # –£–¥–∞–ª—è–µ–º Created, Linked, Grouped (—É–∂–µ –≤ header)
    text = re.sub(r"<p><b>Created:</b>[^<]*</p>", "", text)
    text = re.sub(r"<p><b>Linked block:</b>[^<]*</p>", "", text)
    text = re.sub(r"<p><b>Grouped blocks:</b>[^<]*</p>", "", text)

    # –£–¥–∞–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ –∫—Ä–æ–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    text = re.sub(r'<p><a[^>]*>.*?–û—Ç–∫—Ä—ã—Ç—å –∫—Ä–æ–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.*?</a></p>', "", text, flags=re.DOTALL)

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—ã –ü–ï–†–ï–î –æ—Å—Ç–∞–ª—å–Ω—ã–º HTML
    def process_table_match(match):
        return _table_to_markdown(match.group(0))

    text = re.sub(r"<table[^>]*>.*?</table>", process_table_match, text, flags=re.DOTALL)

    # –ó–∞–≥–æ–ª–æ–≤–∫–∏
    text = re.sub(r"<h1[^>]*>\s*(.*?)\s*</h1>", r"# \1\n", text, flags=re.DOTALL)
    text = re.sub(r"<h2[^>]*>\s*(.*?)\s*</h2>", r"## \1\n", text, flags=re.DOTALL)
    text = re.sub(r"<h3[^>]*>\s*(.*?)\s*</h3>", r"### \1\n", text, flags=re.DOTALL)
    text = re.sub(r"<h4[^>]*>\s*(.*?)\s*</h4>", r"#### \1\n", text, flags=re.DOTALL)

    # –ñ–∏—Ä–Ω—ã–π –∏ –∫—É—Ä—Å–∏–≤
    text = re.sub(r"<b>\s*(.*?)\s*</b>", r"**\1**", text, flags=re.DOTALL)
    text = re.sub(r"<strong>\s*(.*?)\s*</strong>", r"**\1**", text, flags=re.DOTALL)
    text = re.sub(r"<i>\s*(.*?)\s*</i>", r"*\1*", text, flags=re.DOTALL)
    text = re.sub(r"<em>\s*(.*?)\s*</em>", r"*\1*", text, flags=re.DOTALL)

    # –ö–æ–¥
    text = re.sub(r"<code[^>]*>(.*?)</code>", r"`\1`", text, flags=re.DOTALL)
    text = re.sub(r"<pre[^>]*>(.*?)</pre>", r"```\n\1\n```", text, flags=re.DOTALL)

    # –°–ø–∏—Å–∫–∏
    text = re.sub(r"<li>\s*(.*?)\s*</li>", r"- \1\n", text, flags=re.DOTALL)
    text = re.sub(r"<[ou]l[^>]*>", "", text)
    text = re.sub(r"</[ou]l>", "", text)

    # –£–¥–∞–ª—è–µ–º –≤—Å–µ img —Ç–µ–≥–∏ (—É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –≤ sanitize_html, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π)
    text = re.sub(r'<img[^>]*/?>','', text)

    # –°—Å—ã–ª–∫–∏
    text = re.sub(r'<a[^>]*href="([^"]*)"[^>]*>(.*?)</a>', r"[\2](\1)", text, flags=re.DOTALL)

    # –ü–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
    text = re.sub(r"<br\s*/?>", "\n", text)

    # –ü–∞—Ä–∞–≥—Ä–∞—Ñ—ã
    text = re.sub(r"<p[^>]*>\s*(.*?)\s*</p>", r"\1\n", text, flags=re.DOTALL)

    # –£–¥–∞–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è HTML —Ç–µ–≥–∏
    text = re.sub(r"<[^>]+>", "", text)

    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º HTML entities
    text = text.replace("&nbsp;", " ")
    text = text.replace("&amp;", "&")
    text = text.replace("&lt;", "<")
    text = text.replace("&gt;", ">")
    text = text.replace("&quot;", '"')
    text = text.replace("&#39;", "'")

    # –£–¥–∞–ª—è–µ–º –æ—Å—Ç–∞—Ç–æ—á–Ω—ã–µ markdown-—Å—Å—ã–ª–∫–∏ –Ω–∞ –º—É—Å–æ—Ä–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    text = DATALAB_MD_IMG_PATTERN.sub("", text)

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–Ω–æ—Å—ã
    text = re.sub(r"[ \t]+", " ", text)
    text = re.sub(r" *\n *", "\n", text)
    text = re.sub(r"\n{3,}", "\n\n", text)
    text = text.strip()

    return text


def _format_image_ocr_md(data: dict) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ OCR –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π Markdown."""
    img_data = extract_image_ocr_data(data)
    parts = []

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫: [–ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ï] –¢–∏–ø: XXX | –û—Å–∏: XXX
    header_parts = ["**[–ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ï]**"]
    if img_data.get("zone_name") and img_data["zone_name"] != "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ":
        header_parts.append(f"–¢–∏–ø: {img_data['zone_name']}")
    if img_data.get("grid_lines") and img_data["grid_lines"] != "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã":
        header_parts.append(f"–û—Å–∏: {img_data['grid_lines']}")
    if img_data.get("location_text"):
        header_parts.append(img_data["location_text"])
    parts.append(" | ".join(header_parts))

    # –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
    if img_data.get("content_summary"):
        parts.append(f"**–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ:** {img_data['content_summary']}")

    # –î–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
    if img_data.get("detailed_description"):
        parts.append(f"**–û–ø–∏—Å–∞–Ω–∏–µ:** {img_data['detailed_description']}")

    # –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    if img_data.get("clean_ocr_text"):
        parts.append(f"**–¢–µ–∫—Å—Ç –Ω–∞ —á–µ—Ä—Ç–µ–∂–µ:** {img_data['clean_ocr_text']}")

    # –ö–ª—é—á–µ–≤—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏ - —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, –±–µ–∑ backticks
    if img_data.get("key_entities"):
        entities = ", ".join(img_data["key_entities"])
        parts.append(f"**–°—É—â–Ω–æ—Å—Ç–∏:** {entities}")

    return "\n".join(parts) if parts else ""


def _process_ocr_content(ocr_text: str) -> str:
    """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–ª–æ–∫–∞ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ Markdown."""
    if not ocr_text:
        return ""

    text = ocr_text.strip()
    if not text:
        return ""

    # HTML –∫–æ–Ω—Ç–µ–Ω—Ç (–≤–∫–ª—é—á–∞—è —Å–ª—É—á–∞–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å –∑–∞–∫—Ä—ã–≤–∞—é—â–µ–≥–æ —Ç–µ–≥–∞)
    if text.startswith("<") or text.startswith("</"):
        return _html_to_markdown(text)

    # JSON –∫–æ–Ω—Ç–µ–Ω—Ç
    if text.startswith("{") or text.startswith("["):
        try:
            parsed = json_module.loads(text)
            if isinstance(parsed, dict) and is_image_ocr_json(parsed):
                return _format_image_ocr_md(parsed)
            # Fallback –¥–ª—è –¥—Ä—É–≥–æ–≥–æ JSON
            return json_module.dumps(parsed, ensure_ascii=False, separators=(',', ':'))
        except json_module.JSONDecodeError:
            pass

    # –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç - —Ç–∞–∫–∂–µ –ø—Ä–∏–º–µ–Ω—è–µ–º —Å–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏—é markdown
    return sanitize_markdown(text)


def generate_md_from_pages(
    pages: List,
    output_path: str,
    doc_name: str = None,
    project_name: str = None,
) -> str:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ–≥–æ Markdown —Ñ–∞–π–ª–∞ (_document.md) –∏–∑ OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
    –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è LLM.

    Args:
        pages: —Å–ø–∏—Å–æ–∫ Page –æ–±—ä–µ–∫—Ç–æ–≤ —Å –±–ª–æ–∫–∞–º–∏
        output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è MD —Ñ–∞–π–ª–∞
        doc_name: –∏–º—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
        project_name: –∏–º—è –ø—Ä–æ–µ–∫—Ç–∞ (–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ MD)

    Returns:
        –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
    """
    try:
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        title = doc_name or "OCR Result"

        # –°–æ–±–∏—Ä–∞–µ–º –±–ª–æ–∫–∏ –ø–æ –≥—Ä—É–ø–ø–∞–º
        groups = collect_block_groups(pages)

        # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ —à—Ç–∞–º–ø–∞
        inherited_stamp_data = collect_inheritable_stamp_data(pages)

        md_parts = []

        # === HEADER ===
        md_parts.append(f"# {title}")
        md_parts.append("")
        md_parts.append(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC")

        # –®—Ç–∞–º–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞
        if inherited_stamp_data:
            stamp_str = _format_stamp_md(inherited_stamp_data)
            if stamp_str:
                md_parts.append(f"**–®—Ç–∞–º–ø:** {stamp_str}")

        md_parts.append("")
        md_parts.append("---")
        md_parts.append("")

        # === –ë–õ–û–ö–ò - –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º ===
        block_count = 0
        current_page_num = None

        for page in pages:
            page_num = page.page_number + 1 if page.page_number is not None else 0

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –±–ª–æ–∫–∏ –∫—Ä–æ–º–µ —à—Ç–∞–º–ø–æ–≤
            non_stamp_blocks = [b for b in page.blocks if getattr(b, "category_code", None) != "stamp"]
            if not non_stamp_blocks:
                continue

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            if page_num != current_page_num:
                current_page_num = page_num
                md_parts.append(f"## –°–¢–†–ê–ù–ò–¶–ê {page_num}")

                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —à—Ç–∞–º–ø–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–ª–∏—Å—Ç, –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ)
                page_stamp = find_page_stamp(page.blocks)
                if page_stamp:
                    sheet_num = page_stamp.get("sheet_number", "")
                    total_sheets = page_stamp.get("total_sheets", "")
                    sheet_name = page_stamp.get("sheet_name", "")

                    if sheet_num or total_sheets:
                        if total_sheets:
                            md_parts.append(f"**–õ–∏—Å—Ç:** {sheet_num} (–∏–∑ {total_sheets})")
                        else:
                            md_parts.append(f"**–õ–∏—Å—Ç:** {sheet_num}")

                    if sheet_name:
                        md_parts.append(f"**–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞:** {sheet_name}")

                md_parts.append("")

            for block in page.blocks:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–ª–æ–∫–∏ —à—Ç–∞–º–ø–∞
                if getattr(block, "category_code", None) == "stamp":
                    continue

                block_count += 1
                armor_code = get_block_armor_id(block.id)
                block_type = block.block_type.value.upper()

                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∞ - –∫–æ–º–ø–∞–∫—Ç–Ω–æ –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É
                meta_parts = [f"[{block_type}]", f"BLOCK:{armor_code}"]

                # Linked block
                linked_id = getattr(block, "linked_block_id", None)
                if linked_id:
                    meta_parts.append(f"‚Üí{get_block_armor_id(linked_id)}")

                # Grouped blocks
                group_id = getattr(block, "group_id", None)
                if group_id and group_id in groups:
                    group_name = getattr(block, "group_name", None) or "–≥—Ä—É–ø–ø–∞"
                    group_block_ids = [get_block_armor_id(b.id) for b in groups[group_id]]
                    meta_parts.append(f"üì¶{group_name}[{','.join(group_block_ids)}]")

                md_parts.append(" ".join(meta_parts))

                # –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–ª–æ–∫–∞
                content = _process_ocr_content(block.ocr_text)
                if content:
                    md_parts.append(content)

                md_parts.append("")

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–π–ª
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("\n".join(md_parts))

        logger.info(f"MD —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_file} ({block_count} –±–ª–æ–∫–æ–≤)")
        return str(output_file)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ MD: {e}", exc_info=True)
        raise


def generate_md_from_result(
    result: dict, output_path: Path, doc_name: Optional[str] = None
) -> None:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å Markdown —Ñ–∞–π–ª –∏–∑ result.json —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã–º–∏ –±–ª–æ–∫–∞–º–∏.
    –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º.

    Args:
        result: —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ OCR (pages, blocks)
        output_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è MD —Ñ–∞–π–ª–∞
        doc_name: –∏–º—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
    """
    if not doc_name:
        doc_name = result.get("pdf_path", "OCR Result")

    md_parts = []

    # === HEADER ===
    md_parts.append(f"# {doc_name}")
    md_parts.append("")
    md_parts.append(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC")

    # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ —à—Ç–∞–º–ø–∞ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –±–ª–æ–∫–∞
    first_stamp = None
    for page in result.get("pages", []):
        for blk in page.get("blocks", []):
            if blk.get("stamp_data"):
                first_stamp = blk["stamp_data"]
                break
        if first_stamp:
            break

    if first_stamp:
        stamp_str = _format_stamp_md(first_stamp)
        if stamp_str:
            md_parts.append(f"**–®—Ç–∞–º–ø:** {stamp_str}")

    md_parts.append("")
    md_parts.append("---")
    md_parts.append("")

    # –°–æ–±–∏—Ä–∞–µ–º –≥—Ä—É–ø–ø—ã –±–ª–æ–∫–æ–≤
    groups: Dict[str, List[str]] = {}
    for page in result.get("pages", []):
        for blk in page.get("blocks", []):
            group_id = blk.get("group_id")
            if group_id:
                if group_id not in groups:
                    groups[group_id] = []
                groups[group_id].append(blk.get("id", ""))

    # === –ë–õ–û–ö–ò - –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º ===
    block_count = 0
    current_page_num = None

    for page in result.get("pages", []):
        page_num = page.get("page_number", 0)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –±–ª–æ–∫–∏ –∫—Ä–æ–º–µ —à—Ç–∞–º–ø–æ–≤
        non_stamp_blocks = [b for b in page.get("blocks", []) if b.get("category_code") != "stamp"]
        if not non_stamp_blocks:
            continue

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        if page_num != current_page_num:
            current_page_num = page_num
            md_parts.append(f"## –°–¢–†–ê–ù–ò–¶–ê {page_num}")

            # –ò—â–µ–º —à—Ç–∞–º–ø –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ª–∏—Å—Ç–µ
            page_stamp = None
            for blk in page.get("blocks", []):
                if blk.get("category_code") == "stamp":
                    page_stamp = blk.get("stamp_data") or blk.get("ocr_json")
                    break

            if page_stamp:
                sheet_num = page_stamp.get("sheet_number", "")
                total_sheets = page_stamp.get("total_sheets", "")
                sheet_name = page_stamp.get("sheet_name", "")

                if sheet_num or total_sheets:
                    if total_sheets:
                        md_parts.append(f"**–õ–∏—Å—Ç:** {sheet_num} (–∏–∑ {total_sheets})")
                    else:
                        md_parts.append(f"**–õ–∏—Å—Ç:** {sheet_num}")

                if sheet_name:
                    md_parts.append(f"**–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ª–∏—Å—Ç–∞:** {sheet_name}")

            md_parts.append("")

        for blk in page.get("blocks", []):
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –±–ª–æ–∫–∏ —à—Ç–∞–º–ø–∞
            if blk.get("category_code") == "stamp":
                continue

            block_id = blk.get("id", "")
            block_type = blk.get("block_type", "text").upper()
            ocr_html = blk.get("ocr_html", "")
            ocr_text = blk.get("ocr_text", "")

            block_count += 1

            # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∞
            meta_parts = [f"[{block_type}]", f"BLOCK:{block_id}"]

            # Linked block
            if blk.get("linked_block_id"):
                meta_parts.append(f"‚Üí{blk['linked_block_id']}")

            # Grouped blocks
            group_id = blk.get("group_id")
            if group_id and group_id in groups:
                group_name = blk.get("group_name") or "–≥—Ä—É–ø–ø–∞"
                group_block_ids = groups[group_id]
                meta_parts.append(f"üì¶{group_name}[{','.join(group_block_ids)}]")

            md_parts.append(" ".join(meta_parts))

            # –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–ª–æ–∫–∞
            content = ""
            if ocr_html:
                content = _html_to_markdown(ocr_html)
            elif ocr_text:
                content = _process_ocr_content(ocr_text)

            if content:
                md_parts.append(content)
            else:
                md_parts.append("*(–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö)*")

            md_parts.append("")

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(md_parts))

    logger.info(f"MD —Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∏–∑ result.json: {output_path} ({block_count} –±–ª–æ–∫–æ–≤)")
